{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/churn_data.csv\")\n",
    "# Select some features and change the target data type to be integer\n",
    "df = df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip','callcard', 'wireless','churn']]\n",
    "df['churn'] = df['churn'].astype('int')\n",
    "# Let's define our Feature set and our Target\n",
    "Features = np.asarray(df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "Target = np.asarray(df['churn'])\n",
    "Features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset \n",
    "# Data Standardization give data zero mean and unit variance and standard deviation = 1\n",
    "Features = preprocessing.StandardScaler().fit(Features).transform(Features)\n",
    "Features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Target, test_size=0.2, random_state=4)    \n",
    "\n",
    "# Train our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_test_ = model.predict(X_test)\n",
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a column for each possible value of churn, which is 0 or 1. \n",
    "# The first column is the probability of the target being 0 and the second column is the probability of the target being 1.\n",
    "y_test_prob = model.predict_proba(X_test)\n",
    "y_test_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Index\n",
    "#\tJ = 0 : The two sets have no elements in common.\n",
    "#\tJ = 1 : The two sets are identical.\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, y_test_,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# For a binary classification problem, the confusion matrix is a 2x2 table:\n",
    "#                  | Predicted Positive\t| Predicted Negative\n",
    "# _________________|____________________|____________________\n",
    "# Actual Positive  | True Positive (TP)\t| False Negative (FN)\n",
    "# Actual Negative  | False Positive (FP)| True Negative (TN)\n",
    "#\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_, labels=[1,0])\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN) \n",
    "# F1 Score = 2 * (Precision * Recall) / (Precision + Recall) Best=1 Worst=0\n",
    "print (classification_report(y_test, y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Loss\n",
    "# Measures the error between the actual value and the predicted probabilities.\n",
    "# Value of 0 indicates perfect predictions.\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_test_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
