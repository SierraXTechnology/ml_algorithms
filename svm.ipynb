{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from util import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cell_samples.csv\")\n",
    "# Coerce non-numeric values in BareNuc column and remove any rows where the data cannont be coerced\n",
    "df = df[pd.to_numeric(df['BareNuc'], errors='coerce').notnull()]\n",
    "df['BareNuc'] = df['BareNuc'].astype('int')\n",
    "\n",
    "# Select features and target\n",
    "Features = df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']].values\n",
    "# Features = np.asarray(Features) - this is not necessary\n",
    "Features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = df['Class'].values\n",
    "Target[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Features, Target, test_size=0.2, random_state=4)\n",
    "print('Train set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the kernel function, and can be of different types, such as:\n",
    "\n",
    "    1.Linear\n",
    "    2.Polynomial\n",
    "    3.Radial basis function (RBF)\n",
    "    4.Sigmoid\n",
    "Each of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset. We usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_test_ = model.predict(X_test)\n",
    "print(y_test_[0:5])\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "- Confusion Matrix \n",
    "- F1 Score\n",
    "- Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Confusion Matrix\n",
    "# For a binary classification problem, the confusion matrix is a 2x2 table:\n",
    "#                  | Predicted Positive\t| Predicted Negative\n",
    "# _________________|____________________|____________________\n",
    "# Actual Positive  | True Positive (TP)\t| False Negative (FN)\n",
    "# Actual Negative  | False Positive (FP)| True Negative (TN)\n",
    "#\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_, labels=[2,4])\n",
    "cnf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=['Benign(2)', 'Malignant(4)'], normalize=False, title='Confusion matrix')\n",
    "print (classification_report(y_test, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score\n",
    "- F1 = 1 : Perfect precision and recall.\n",
    "- F1 = 0 : Either precision or recall is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_test_, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jaccard Score\n",
    "- J = 1 : Perfect match between the predicted and true labels.\n",
    "- J = 0 : No overlap between the predicted and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "print('jaccard_score for 2: ',jaccard_score(y_test, y_test_, pos_label=2))\n",
    "print('jaccard_score for 4: ',jaccard_score(y_test, y_test_, pos_label=4))\n",
    "print('jaccard_score for weighted: ',jaccard_score(y_test, y_test_, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
